# 線性分類

在上一章節中，我們介紹了影像分類問題，那就是給定一個影像，從一個固定類別中預測這張圖片是屬於哪個類別。此外，我們還介紹了 K 個最近鄰居分類器，基本的想法就是訓練資料集中找到最接近測試圖片的結果。如同我們所看到的，這種方法有底下幾個缺點：

- 這種分類器在針對測試資料進行比對時，需要記住所有的訓練資料，當你的訓練資料非常大時，這是很沒有效率的。
- 針對測試資料進行分類時，需要比較所有的訓練資料。

**概述** 我們會開始開發一個更強大的影像分類方法，這種方法最終可以延伸到神經網路和卷積神經網路。此方法包含兩個主要部分：評價函數 (score function) 和損失函數 (loss functino)。評價函數用來計算原始資料對應到每個類別的分數、而損失函數用來量化預測的結果和真實結果之間的差距。這種方式可以轉換成一個最佳化問題，我們想要達到的目標就是透過評價函數的參數來最小化損失函數。

## 從圖片到標籤的分數映射

這種方法的第一步是要定義一個評價函數，這個評價函數用來產生每個像素值對應到每個類別的信心分數。底下我們來看一個具體的範例。現在我們假設訓練資料集包含 i 張圖片，xi∈RD，每張圖片有一個類別 yi，i 從 1 到 N，同時 yi∈1…K。換言之，我們有 N 張圖片 (每張圖片是 D 維)，共有 K 個類別。舉例來說，在 CIFAR-10 中，我們的訓練資料集 N = 50,000 張圖片，每張圖片的維度 D = 32*32*3 = 3072，K = 10，因為總共有十種類別 (狗、貓、車 ... 等)。現在，我們要定義一個評價函數 f:RD↦RK，用來將原始像素映射到類別的分數。

**線性分類器**. 讓我們從最簡單的機率函數開始，底下是一個線性映射：

![img](https://raw.githubusercontent.com/kevingo/CS231n-Convolutional-Neural-Networks-for-Visual-Recognition/master/images/e1.gif)

在上面的等式中，我們將每一張圖片的像素視為一個攤平的單一維度的向量，大小為 [D x 1]。**W** 矩陣 (大小為 [K x D]) 和 **b** 向量 (大小為 [K x 1]) 則視為該函數的參數。在 CIFAR-10 中，xi 就包含了第 i 張圖片的像素資訊，這張圖片被攤平為 [3072 x 1] 的向量，**W** 是 [10 x 3072]，而 **b** 是 [10 x 1]。因此，此函數的輸入是 3072 個數字 (原始像素值)，輸出為 10 個數字 (不同類別的分數)。參數 **W** 稱為**權重**，**b** 稱為**誤差向量**，因為它會影響輸出的數值，但不會直接和資料 xi 產生關聯。有時候，你會聽到人們常常混用**權重 (weight)** 和**參數 (parameters)**。
